{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c440a81-1c06-4b85-8c7a-187b716023a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Why Parallel programming?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a6e083-5dcf-4a17-828b-d7b1cfcd6693",
   "metadata": {},
   "source": [
    "## Instruction Level Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1aa694-e12d-42e6-a2f8-d15c8184dedd",
   "metadata": {},
   "source": [
    "* Processor hardware optimizes low-level instruction execution\n",
    "* **Instruction pipelining:** Overlapped execution of serial instructions\n",
    "* **Superscalar execution:** Multiple units of one processor are used in parallel\n",
    "* **Out-of-order execution:** reorder instructions that do not have data depedencies\n",
    "* **Speculative execution:** Control flow speculation and branch prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec14ee26-8e8e-4edb-a4d5-eaf51b29fa57",
   "metadata": {},
   "source": [
    "|                                                                                                Why ***Parallel*** computing                                                                                               |                                      Why parallel ***programming***                                     |\n",
    "|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------|\n",
    "| There are problems that cannot be made with <br>the current speed, because we reach the Brick Wall.                                                                                                                 | Auto-parallelism does not work well. It is <br>very inefficient. Possible only with certain codes |\n",
    "| **Power Wall:** Because of Physical reasons it is <br>not possible to maintain a stable consumption of Power. <br><br> **Memory Wall:**<br>- Latency of response in the <br>memory with the CPU creates a Bottleneck<br><br>**Instruction Level Parallelism (ILP) Wall:** <br>- No longer cost-effective to dedicate new transistors <br>to ILP Mechanism <br>- Deeper pipilines make the power problem worse<br>- High ILP complexity effectively reduces the<br>processing speed for a given frequency  | Not possible for a lot of applications with auto-parallelism.                                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59a2a64-b594-47cc-a592-3c17fd09c974",
   "metadata": {},
   "source": [
    "# Types of Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5accff-0a12-4611-ab13-2aec78330629",
   "metadata": {},
   "source": [
    "| Functional Parallelism                                                                                                 | Data Parallelism                                                                                                      |\n",
    "|------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n",
    "| Views problem as a stream of instructions<br> that can be broken down into functions <br>to be executed simultaneously | View problem as an amount of data that can be broken down<br>into chunks to be independently operated upon (eg. code) |\n",
    "| Each processing Element performs a different function                                                                  | Each processing Element performs a same function on<br>different piece of data                                        |\n",
    "| Pipeline, Line of Production                                                                                           | Signal Processing                                                                                                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6485b797-d6f0-46f2-ba82-33c743dac025",
   "metadata": {},
   "source": [
    "# Memory Achitecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0778cbc9-4c73-46bb-ba5e-7441c10da488",
   "metadata": {},
   "source": [
    "<img src=\"img/mem_arch.png\" alt=\"Memory Architecture\" width=\"80%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9ebd56-023c-4037-8dfa-e9fa0d5c108e",
   "metadata": {},
   "source": [
    "## Shared Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549dc10-0fc5-4743-84d0-7a5977f592a7",
   "metadata": {},
   "source": [
    "| Uniform Memory Access (UMA)                        | Non-uniform memory access (NUMA)                  | Cache-coherent NUMA systems                                                 |\n",
    "|----------------------------------------------------------|---------------------------------------------------------|---------------------------------------------------------------------------------|\n",
    "| Each CPU has same access time to <br>each memory address | Memory has affinity to a processor                      | Distributed database storing location<br>and status cache of lines              |\n",
    "| Simple design but limited scalability                    | Access to local memory faster than <br>to remote memory | Requires fast hardware because it must <br>be queried on every memory reference |\n",
    "|                                                          | Harder to program but more scalable                     |                                                                                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1499432-a879-46f6-a698-e9734667cc0a",
   "metadata": {},
   "source": [
    "<img src=\"img/types_mem.png\" alt=\"Memory Architecture\" width=\"80%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd14936-4679-4903-a1ef-38c44bbab990",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Single-threaded vs. multi-threaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac4fe0f-277c-49cc-8ccb-5022775ee8ad",
   "metadata": {},
   "source": [
    "* All modern, pipelined CPUs suffer from the following problem\n",
    "    * When a memory reference misses L1 or L2 caches, it takes a long time until the requested word is loaded into the cache\n",
    "* On-chip multithreading allows the CPU to manage multiple threads to mask these stalls\n",
    "* If one thread is stalled, the CPU can run another thread and keep the hardware busy\n",
    "* Four hardware threads per core often sufficient to hide latency.\n",
    "\n",
    "Knowning the amount of threads allow to have concurrency with the HW can be made using the `std::thread::hardware_concurrency` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6aef0ed-5e32-446a-afc4-2cb1525e11d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 concurrent threads are supported.\n"
     ]
    }
   ],
   "source": [
    "#include <iostream>\n",
    "#include <thread>\n",
    "\n",
    "unsigned int n = std::thread::hardware_concurrency();\n",
    "std::cout << n << \" concurrent threads are supported.\\n\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1249b5-34ab-4c84-bf04-ef7a4f28a663",
   "metadata": {},
   "source": [
    "<img src=\"img/sing-multi-thread.png\" alt=\"Memory Architecture\" width=\"60%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82318402-d671-419e-8cad-680e8b9ef323",
   "metadata": {},
   "source": [
    "# Concurrency in C++"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fcf19f-397c-4665-9f9d-78ca7a333848",
   "metadata": {},
   "source": [
    "* the thread library is a set of components supporting traditional threads-and-locks-style system-level concurrent programming\n",
    "    * threads\n",
    "    * condition_variable\n",
    "    * mutex\n",
    "    * etc\n",
    "* A task support library facilities supporting task-level concurrent programming\n",
    "    * future\n",
    "    * promise\n",
    "    * packaged_task\n",
    "    * async()\n",
    "* Memory model – a set of guarantees for concurrent access to memory that basically ensures that simple and ordinary access works as one would naively expect\n",
    "* Support for programming without locks – fine-grained low-level mechanisms for avoiding data races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b156f05-a97c-4090-a6c0-43bc01df5137",
   "metadata": {},
   "outputs": [],
   "source": [
    "void hello() {\n",
    "    std::cout<<\"Hello Concurrent World\\n\";\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1adb3da1-1153-4b25-80aa-998002cc23af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Concurrent World\n"
     ]
    }
   ],
   "source": [
    "std::thread my_thread(hello);\n",
    "my_thread.join();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d58595cc-9eb6-4242-a6f4-18325eabcf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Concurrent World\n",
      "This is another message from concurrent world\n"
     ]
    }
   ],
   "source": [
    "std::thread lamba_thread([]{\n",
    "    std::cout<<\"Hello Concurrent World\\n\";\n",
    "    std::cout<<\"This is another message from concurrent world\\n\";\n",
    "});\n",
    "lamba_thread.join();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c16e3a-a1eb-4119-a3ae-2ca66a43ffba",
   "metadata": {},
   "source": [
    "# Background Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c467d07d-7d2b-4844-9c12-b427621e3c35",
   "metadata": {},
   "source": [
    "* `detach()` leaves the thread to run in the background without any means of communicating with it\n",
    "    * No longer joinable\n",
    "    * Ownership and control passed to the C++ runtime system\n",
    "* Detached threads often called **daemon** threads after the UNIX concept of a daemon process that runs in the background\n",
    "* Typically Long Running: There is a discussion about the behavior after the *Termination* of the main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662542bb-0726-454c-9700-c56f60ac5190",
   "metadata": {},
   "source": [
    "# Cooperative Cancellation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0afffae-b923-4c37-b465-ee19ffabd9ed",
   "metadata": {},
   "source": [
    "C++20 provides `std::stop_source` and `std::stop_token` classes to handle a purely cooperative cancellation.\n",
    "\n",
    "The new thread class in C++20 `std::jthread` integrates with `std::stop_token` to support cooperative cancellation.\n",
    "* Destroying a std::jthread calls source.request_stop() and thread.join().\n",
    "* The thread needs to check the stop token passed into the thread function.\n",
    "\n",
    "```cpp\n",
    "void thread_func(std::stop_token st, int arg1, int arg2) {\n",
    "    while(!st.stop_requested()){\n",
    "        do_stuff(arg1,arg2);\n",
    "    }\n",
    "}\n",
    "\n",
    "void foo(int i) {\n",
    "    std::jthread t(thread_func, i, 42);\n",
    "    do_another_stuff();\n",
    "} // destructor requests stop and joins\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c44b2e-db61-48fb-9412-78066ee0ebb8",
   "metadata": {},
   "source": [
    "# Identifying threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29c81ed-e87c-4ace-ba5f-f428225f41e7",
   "metadata": {},
   "source": [
    "Thread identifiers are of type `std::thread::id`\n",
    "\n",
    "* Can be obtained in two ways\n",
    "    * `get_id()` member function\n",
    "    * `std::this_thread::get_id()`\n",
    "* If thread object does not have an associated thread of execution, `get_id()` returns default constructed `std::thread::id` object\n",
    "    * Indicates “not any thread”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "475249c4-22dc-4f41-ba67-75f8e3aa06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <thread>\n",
    "#include <chrono>\n",
    " \n",
    "void foo() {\n",
    "    std::this_thread::sleep_for(std::chrono::seconds(1));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3516a51-0cd6-4fe0-ba8e-c5529f7c541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1's id: 139640200578816\n",
      "t2's id: 139639989991168\n"
     ]
    }
   ],
   "source": [
    "std::thread t1(foo);\n",
    "std::thread::id t1_id = t1.get_id();\n",
    "\n",
    "std::thread t2(foo);\n",
    "std::thread::id t2_id = t2.get_id();\n",
    "\n",
    "std::cout << \"t1's id: \" << t1_id << '\\n';\n",
    "std::cout << \"t2's id: \" << t2_id << '\\n';\n",
    "\n",
    "t1.join();\n",
    "t2.join();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3a325d-e85b-4496-b1ed-f9ccf80ec989",
   "metadata": {},
   "source": [
    "# Sharing data between threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672155f-bc51-48ac-bfa8-761f6794b9b6",
   "metadata": {},
   "source": [
    "* No problem as long as all accesses are read only\n",
    "* *Problems begin as soon as at least one threads modifies shared data*\n",
    "* Problems often related to **Invariants**\n",
    "    * **Invariants:** Statements about a particular data structure that should always be true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de36f29-a10a-439d-b50e-eba04bfb512b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Race condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47feda38-5a01-4f26-a26a-935c8a1ad407",
   "metadata": {},
   "source": [
    "<img src=\"img/race_condition.png\" alt=\"Race Condition\" width=\"70%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790dd7b1-6b5f-46de-8861-1d0e2c39f5ae",
   "metadata": {},
   "source": [
    "* Causes non-deterministic program behavior\n",
    "    * Failure in programs expected to be deterministic\n",
    "* Often benign – if all possible outcomes are acceptable\n",
    "    * Example: often the order in which items are added to a queue does not matter – as long as all invariants are maintained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc42cb37-958a-4906-b7cf-e297ebf8be01",
   "metadata": {},
   "source": [
    "## Data Race condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5960c28-f54c-4b15-8f9d-959535242954",
   "metadata": {},
   "source": [
    "<img src=\"img/data_race.png\" alt=\"Data Race Condition\" width=\"70%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee36ca-be8b-4642-8a30-2f2fb221566a",
   "metadata": {},
   "source": [
    "<img src=\"img/data_race_types.png\" alt=\"Data Race Condition Types\" width=\"70%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b15d0c0-ba75-4a45-bea1-31ec21b066da",
   "metadata": {},
   "source": [
    "## Protecting shared data with mutexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30546bcd-b7fd-450f-b406-bc46a400d97e",
   "metadata": {},
   "source": [
    "Mutexes ensure mutual exclusion during access to a data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08a0276-c6c3-40e1-957b-0af51fb92df1",
   "metadata": {},
   "source": [
    "<img src=\"img/mutexes.png\" alt=\"Mutexes\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1b8444b-c80d-4377-af49-1fa8ab2377dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <mutex>\n",
    "#include <list>\n",
    "#include <thread>\n",
    "#include <vector>\n",
    "#include <iostream>\n",
    "\n",
    "#define NUMBER_OF_THREADS 10\n",
    "\n",
    "std::list<int> some_list;\n",
    "std::mutex some_mutex;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d456478e-70d8-40ac-96ae-a82d12ab2407",
   "metadata": {},
   "outputs": [],
   "source": [
    "void add_to_list(int new_value) {\n",
    "    std::lock_guard<std::mutex> guard(some_mutex);\n",
    "    some_list.push_back(new_value);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41855ec6-0fa2-4de3-b875-9fdc04c859ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of list with mutex: 10\n",
      "Element in list with mutex: 0\n",
      "Element in list with mutex: 8\n",
      "Element in list with mutex: 12\n",
      "Element in list with mutex: 28\n",
      "Element in list with mutex: 32\n",
      "Element in list with mutex: 36\n",
      "Element in list with mutex: 20\n",
      "Element in list with mutex: 16\n",
      "Element in list with mutex: 24\n",
      "Element in list with mutex: 4\n"
     ]
    }
   ],
   "source": [
    "// Test with Mutex\n",
    "std::vector<std::thread> threads;\n",
    "\n",
    "for (int i = 0; i < NUMBER_OF_THREADS; i++) {\n",
    "    threads.emplace_back(add_to_list, i * 4);\n",
    "}\n",
    "\n",
    "for (auto& t : threads) {\n",
    "    t.join();\n",
    "}\n",
    "\n",
    "std::cout << \"Size of list with mutex: \" << some_list.size() << std::endl;\n",
    "for (auto& n : some_list) {\n",
    "    std::cout << \"Element in list with mutex: \" << n << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ddb8f3-5e4d-4398-badc-fe1d017c4322",
   "metadata": {},
   "source": [
    "## Deadlock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34af06f-0056-4b4e-a6c8-58ad74e596c8",
   "metadata": {},
   "source": [
    "<img src=\"img/deadlock_def.png\" alt=\"Deadlock definition\" width=\"70%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde7499f-521e-46e5-ab95-e4dba313f4fc",
   "metadata": {},
   "source": [
    "* Can occur when multiple threads simultaneously try to lock multiple mutex variables\n",
    "* Example - two threads T 1 and T 2 and two mutex variables ma and mb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fc805b-a9fa-4442-87a8-2db9d2ed52e7",
   "metadata": {},
   "source": [
    "## Unique Locks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada09f2-1a7c-450f-a638-fcd8d7c44f13",
   "metadata": {},
   "source": [
    "Does not have to own the mutex\n",
    "* Locking can be deferred\n",
    "* Mutex can be unlocked before object is destroyed (via unlock())\n",
    "* Movable\n",
    "* More flexible – but incurs some overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0684d69d-60d1-4a44-87a1-6b91bc6e84c2",
   "metadata": {},
   "source": [
    "## Condition variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95319f52-4f21-4da6-9bdf-17c10fd5b3cd",
   "metadata": {},
   "source": [
    "* Can be used to wait for an event\n",
    "* Associated with an event or condition\n",
    "* One or more threads can wait for the condition to be satisfied\n",
    "* Thread that establishes the condition can notify waiting thread(s) and wake them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6d02dda-817d-408e-bfde-32eeb9e82ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <string>\n",
    "#include <thread>\n",
    "#include <mutex>\n",
    "#include <condition_variable>\n",
    " \n",
    "std::mutex m;\n",
    "std::condition_variable cv;\n",
    "std::string data;\n",
    "bool ready = false;\n",
    "bool processed = false;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9127d29-ec01-459c-acb4-8a2afd5b3267",
   "metadata": {},
   "outputs": [],
   "source": [
    "void worker_thread() {\n",
    "    // Wait until main() sends data\n",
    "    std::unique_lock<std::mutex> lk(m);\n",
    "    cv.wait(lk, []{return ready;});\n",
    " \n",
    "    // after the wait, we own the lock.\n",
    "    std::cout << \"Worker thread is processing data\\n\";\n",
    "    data += \" after processing\";\n",
    " \n",
    "    // Send data back to main()\n",
    "    processed = true;\n",
    "    std::cout << \"Worker thread signals data processing completed\\n\";\n",
    " \n",
    "    // Manual unlocking is done before notifying, to avoid waking up\n",
    "    // the waiting thread only to block again (see notify_one for details)\n",
    "    lk.unlock();\n",
    "    cv.notify_one();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "776f686b-06e5-4d81-9cd9-b97ae8d487c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main() signals data ready for processing\n",
      "Worker thread is processing data\n",
      "Worker thread signals data processing completed\n",
      "Back in main(), data = Example data after processing\n"
     ]
    }
   ],
   "source": [
    "std::thread worker(worker_thread);\n",
    " \n",
    "data = \"Example data\";\n",
    "// send data to the worker thread\n",
    "{\n",
    "    std::lock_guard<std::mutex> lk(m);\n",
    "    ready = true;\n",
    "    std::cout << \"main() signals data ready for processing\\n\";\n",
    "}\n",
    "cv.notify_one();\n",
    "\n",
    "// wait for the worker\n",
    "{\n",
    "    std::unique_lock<std::mutex> lk(m);\n",
    "    cv.wait(lk, []{return processed;});\n",
    "}\n",
    "std::cout << \"Back in main(), data = \" << data << '\\n';\n",
    "\n",
    "worker.join();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38126ed-7aa1-4f0e-aabc-67f042fd27cd",
   "metadata": {},
   "source": [
    "The `conditional_variable` can be used to wait for an event. One or more threads are going to wait for the predicated to be true. The `condition_variable` uses a `mutex` to block the access to the information. If the condition is not fulfil, the `condition_variable` will unlock the `mutex`, block the thread and saves its id to unlock when there is a `notify_one` or `notify_all`\n",
    "\n",
    "The bigger difference between Condition Variables and Mutex is that the first ones can be used to implement *temporal ordering* between threads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81dd73c-10f2-423e-a68c-843b35749cda",
   "metadata": {},
   "source": [
    "## Semaphores C++20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73df7f0-392a-4a14-b699-4e4e15b60ff6",
   "metadata": {},
   "source": [
    "* A semaphore represents a number of available \"slots\". If you acquire a slot on the semaphore then the count is decreased until you release the slot.\n",
    "* Attempting to acquire a slot when the count is zero will either block or fail.\n",
    "* A thread may release a slot without acquiring one and vice versa.\n",
    "\n",
    "```cpp\n",
    "std::counting_semaphore<5> slots(5);\n",
    "\n",
    "void func(){\n",
    "    slots.acquire();\n",
    "    do_stuff(); // at most 5 threads can be here\n",
    "    slots.release();\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ef4ea3-ec2c-4589-b73a-77db674087b0",
   "metadata": {},
   "source": [
    "## Waiting for an asynchronous event / task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827ea197-18ff-41b4-804b-4dedb12a590c",
   "metadata": {},
   "source": [
    "<img src=\"img/future.png\" alt=\"Use of Future in C++\" width=\"70%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a5def-ed2c-4923-9eda-083dbbcc123d",
   "metadata": {},
   "source": [
    "* Starts an asynchronous task for which you don’t need the result right away\n",
    "* Returns future object, which will eventually hold the value of the return function\n",
    "* Calling `get()` on the future blocks the thread until future is ready and returns the value\n",
    "* Allows additional arguments to be passed to the function – in the same way as `std::thread`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95f3ef89-99b9-43b4-b8e3-374baf2144b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <string>\n",
    "#include <chrono>\n",
    "#include <thread>\n",
    "\n",
    "std::string fetchDataFromDB(std::string recvdData) {\n",
    "    // Make sure that function takes 5 seconds to complete\n",
    "    std::this_thread::sleep_for(std::chrono::seconds(2));\n",
    "    //Do stuff like creating DB Connection and fetching Data\n",
    "    return \"DB_\" + recvdData;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0e402b2-1b7c-48b0-ad5a-d7f7d7ebf22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::string fetchDataFromFile(std::string recvdData) {\n",
    "    // Make sure that function takes 5 seconds to complete\n",
    "    std::this_thread::sleep_for(std::chrono::seconds(2));\n",
    "    //Do stuff like fetching Data File\n",
    "    return \"File_\" + recvdData;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b52764f-eabc-48ce-9812-107cd14d70df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time Taken = 4 Seconds\n",
      "Data = DB_Data :: File_Data\n"
     ]
    }
   ],
   "source": [
    "// Single thread without async\n",
    "#include <iostream>\n",
    "#include <string>\n",
    "#include <chrono>\n",
    "#include <thread>\n",
    "\n",
    "// Get Start Time\n",
    "std::chrono::system_clock::time_point start = std::chrono::system_clock::now();\n",
    "//Fetch Data from DB\n",
    "std::string dbData = fetchDataFromDB(\"Data\");\n",
    "//Fetch Data from File\n",
    "std::string fileData = fetchDataFromFile(\"Data\");\n",
    "// Get End Time\n",
    "auto end = std::chrono::system_clock::now();\n",
    "auto diff = std::chrono::duration_cast < std::chrono::seconds > (end - start).count();\n",
    "std::cout << \"Total Time Taken = \" << diff << \" Seconds\" << std::endl;\n",
    "//Combine The Data\n",
    "std::string data = dbData + \" :: \" + fileData;\n",
    "//Printing the combined Data\n",
    "std::cout << \"Data = \" << data << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131c6a74-b3ac-488c-bd64-0c7cf0d000b9",
   "metadata": {},
   "source": [
    "The code in `std::async` should be something like:\n",
    "\n",
    "```cpp\n",
    "// Get Start Time\n",
    "system_clock::time_point start = system_clock::now();\n",
    "std::future<std::string> resultFromDB = std::async(std::launch::async, fetchDataFromDB, \"Data\");\n",
    "//Fetch Data from File\n",
    "std::string fileData = fetchDataFromFile(\"Data\");\n",
    "//Fetch Data from DB\n",
    "// Will block till data is available in future<std::string> object.\n",
    "std::string dbData = resultFromDB.get();\n",
    "// Get End Time\n",
    "auto end = system_clock::now();\n",
    "auto diff = duration_cast < std::chrono::seconds > (end - start).count();\n",
    "std::cout << \"Total Time Taken = \" << diff << \" Seconds\" << std::endl;\n",
    "//Combine The Data\n",
    "std::string data = dbData + \" :: \" + fileData;\n",
    "//Printing the combined Data\n",
    "std::cout << \"Data = \" << data << std::endl;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d0ec11-0363-4480-98e5-e1963519cd2e",
   "metadata": {},
   "source": [
    "## Using `std::packaged_task`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7f5516-f747-463c-80a6-d429c3ef87d3",
   "metadata": {},
   "source": [
    "`std::packaged_task<>` is a class template and represents a asynchronous task. It encapsulates,\n",
    "\n",
    "* A callable entity i.e either function, lambda function or function object.\n",
    "* A shared state that stores the value returned or thrown exception by associated callback.\n",
    "\n",
    "The idea is to have more control over the execution than with a normal `std::async` call. This would allow us to execute the `std::package_task` in a specific `thread` and in a specific time.\n",
    "\n",
    "For mote details about the difference between `std::package_task` and `std::future` go to this StackOverflow [Question](https://stackoverflow.com/questions/18143661/what-is-the-difference-between-packaged-task-and-async#:~:text=Use%20std%3A%3Aasync%20if,threads%20or%20call%20them%20later.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed9b8d9-b12f-437a-8aa9-6cfb628e8c15",
   "metadata": {},
   "source": [
    "```cpp\n",
    "// Fetch some data from DB\n",
    "std::string getDataFromDB( std::string token)\n",
    "{\n",
    "    // Do some stuff to fetch the data\n",
    "    std::string data = \"Data fetched from DB by Filter :: \" + token;\n",
    "    return data;\n",
    "}\n",
    "int main()\n",
    "{\n",
    "    // Create a packaged_task<> that encapsulated the callback i.e. a function\n",
    "    std::packaged_task<std::string (std::string)> task(getDataFromDB);\n",
    "    // Fetch the associated future<> from packaged_task<>\n",
    "    std::future<std::string> result = task.get_future();\n",
    "    // Pass the packaged_task to thread to run asynchronously\n",
    "    std::thread th(std::move(task), \"Arg\");\n",
    "    // Join the thread. Its blocking and returns when thread is finished.\n",
    "    th.join();\n",
    "    // Fetch the result of packaged_task<> i.e. value returned by getDataFromDB()\n",
    "    std::string data =  result.get();\n",
    "    std::cout <<  data << std::endl;\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "Expected Output:\n",
    "\n",
    "```bash\n",
    "Data fetched from DB by Filter :: Arg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5405e195-f281-47ef-a179-c21e4d4d6062",
   "metadata": {},
   "source": [
    "## Using Promises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8fc4ff-64b4-406a-92eb-52af75a79208",
   "metadata": {},
   "source": [
    "The promise has a similar principle as the `std::package_task` with the difference that the `std::promise` could set the value of the future in any moment of the function. Meanwhile, the `std::package_task` only could do that as return of the value of the function.\n",
    "\n",
    "Because of that `std::promise` could also be used inside of methods as parameter that does not have the need to return values.\n",
    "\n",
    "The `std::promise` cannot be copied, therefore is has to always be used with the `std::move` parameter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
