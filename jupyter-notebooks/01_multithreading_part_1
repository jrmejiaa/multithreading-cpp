{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16e32539",
   "metadata": {},
   "source": [
    "<!--TABLE OF CONTENTS-->\n",
    "Table of Contents:\n",
    "  - [Why Parallel programming?](#Why-Parallel-programming?)\n",
    "    - [Instruction Level Parallelism](#Instruction-Level-Parallelism)\n",
    "  - [Types of Parallelism](#Types-of-Parallelism)\n",
    "  - [Memory Achitecture](#Memory-Achitecture)\n",
    "  - [Shared Memory](#Shared-Memory)\n",
    "  - [Single-threaded vs. multi-threaded](#Single-threaded-vs.-multi-threaded)\n",
    "  - [Concurrency in C++](#Concurrency-in-C++)\n",
    "  - [Background Threads](#Background-Threads)\n",
    "  - [Cooperative Cancellation](#Cooperative-Cancellation)\n",
    "  - [Identifying threads](#Identifying-threads)\n",
    "  - [Sharing data between threads](#Sharing-data-between-threads)\n",
    "    - [Race condition](#Race-condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c440a81-1c06-4b85-8c7a-187b716023a8",
   "metadata": {},
   "source": [
    "# Why Parallel programming?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a6e083-5dcf-4a17-828b-d7b1cfcd6693",
   "metadata": {},
   "source": [
    "## Instruction Level Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1aa694-e12d-42e6-a2f8-d15c8184dedd",
   "metadata": {},
   "source": [
    "* Processor hardware optimizes low-level instruction execution\n",
    "* **Instruction pipelining:** Overlapped execution of serial instructions\n",
    "* **Superscalar execution:** Multiple units of one processor are used in parallel\n",
    "* **Out-of-order execution:** reorder instructions that do not have data depedencies\n",
    "* **Speculative execution:** Control flow speculation and branch prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec14ee26-8e8e-4edb-a4d5-eaf51b29fa57",
   "metadata": {},
   "source": [
    "|                                                                                                Why ***Parallel*** computing                                                                                               |                                      Why parallel ***programming***                                     |\n",
    "|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------|\n",
    "| There are problems that cannot be made with <br>the current speed, because we reach the Brick Wall.                                                                                                                 | Auto-parallelism does not work well. It is <br>very inefficient. Possible only with certain codes |\n",
    "| **Power Wall:** Because of Physical reasons it is <br>not possible to maintain a stable consumption of Power. <br><br> **Memory Wall:**<br>- Latency of response in the <br>memory with the CPU creates a Bottleneck<br><br>**Instruction Level Parallelism (ILP) Wall:** <br>- No longer cost-effective to dedicate new transistors <br>to ILP Mechanism <br>- Deeper pipilines make the power problem worse<br>- High ILP complexity effectively reduces the<br>processing speed for a given frequency  | Not possible for a lot of applications with auto-parallelism.                                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59a2a64-b594-47cc-a592-3c17fd09c974",
   "metadata": {},
   "source": [
    "# Types of Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5accff-0a12-4611-ab13-2aec78330629",
   "metadata": {},
   "source": [
    "| Functional Parallelism                                                                                                 | Data Parallelism                                                                                                      |\n",
    "|------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n",
    "| Views problem as a stream of instructions<br> that can be broken down into functions <br>to be executed simultaneously | View problem as an amount of data that can be broken down<br>into chunks to be independently operated upon (eg. code) |\n",
    "| Each processing Element performs a different function                                                                  | Each processing Element performs a same function on<br>different piece of data                                        |\n",
    "| Pipeline, Line of Production                                                                                           | Signal Processing                                                                                                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6485b797-d6f0-46f2-ba82-33c743dac025",
   "metadata": {},
   "source": [
    "# Memory Achitecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0778cbc9-4c73-46bb-ba5e-7441c10da488",
   "metadata": {},
   "source": [
    "<img src=\"img/mem_arch.png\" alt=\"Memory Architecture\" width=\"80%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9ebd56-023c-4037-8dfa-e9fa0d5c108e",
   "metadata": {},
   "source": [
    "## Shared Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549dc10-0fc5-4743-84d0-7a5977f592a7",
   "metadata": {},
   "source": [
    "| Uniform Memory Access (UMA)                        | Non-uniform memory access (NUMA)                  | Cache-coherent NUMA systems                                                 |\n",
    "|----------------------------------------------------------|---------------------------------------------------------|---------------------------------------------------------------------------------|\n",
    "| Each CPU has same access time to <br>each memory address | Memory has affinity to a processor                      | Distributed database storing location<br>and status cache of lines              |\n",
    "| Simple design but limited scalability                    | Access to local memory faster than <br>to remote memory | Requires fast hardware because it must <br>be queried on every memory reference |\n",
    "|                                                          | Harder to program but more scalable                     |                                                                                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1499432-a879-46f6-a698-e9734667cc0a",
   "metadata": {},
   "source": [
    "<img src=\"img/types_mem.png\" alt=\"Memory Architecture\" width=\"80%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd14936-4679-4903-a1ef-38c44bbab990",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Single-threaded vs. multi-threaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac4fe0f-277c-49cc-8ccb-5022775ee8ad",
   "metadata": {},
   "source": [
    "* All modern, pipelined CPUs suffer from the following problem\n",
    "    * When a memory reference misses L1 or L2 caches, it takes a long time until the requested word is loaded into the cache\n",
    "* On-chip multithreading allows the CPU to manage multiple threads to mask these stalls\n",
    "* If one thread is stalled, the CPU can run another thread and keep the hardware busy\n",
    "* Four hardware threads per core often sufficient to hide latency.\n",
    "\n",
    "Knowning the amount of threads allow to have concurrency with the HW can be made using the `std::thread::hardware_concurrency` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6aef0ed-5e32-446a-afc4-2cb1525e11d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 concurrent threads are supported.\n"
     ]
    }
   ],
   "source": [
    "#include <iostream>\n",
    "#include <thread>\n",
    "\n",
    "unsigned int n = std::thread::hardware_concurrency();\n",
    "std::cout << n << \" concurrent threads are supported.\\n\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1249b5-34ab-4c84-bf04-ef7a4f28a663",
   "metadata": {},
   "source": [
    "<img src=\"img/sing-multi-thread.png\" alt=\"Memory Architecture\" width=\"60%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82318402-d671-419e-8cad-680e8b9ef323",
   "metadata": {},
   "source": [
    "# Concurrency in C++"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fcf19f-397c-4665-9f9d-78ca7a333848",
   "metadata": {},
   "source": [
    "* the thread library is a set of components supporting traditional threads-and-locks-style system-level concurrent programming\n",
    "    * threads\n",
    "    * condition_variable\n",
    "    * mutex\n",
    "    * etc\n",
    "* A task support library facilities supporting task-level concurrent programming\n",
    "    * future\n",
    "    * promise\n",
    "    * packaged_task\n",
    "    * async()\n",
    "* Memory model – a set of guarantees for concurrent access to memory that basically ensures that simple and ordinary access works as one would naively expect\n",
    "* Support for programming without locks – fine-grained low-level mechanisms for avoiding data races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b156f05-a97c-4090-a6c0-43bc01df5137",
   "metadata": {},
   "outputs": [],
   "source": [
    "void hello() {\n",
    "    std::cout<<\"Hello Concurrent World\\n\";\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1adb3da1-1153-4b25-80aa-998002cc23af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Concurrent World\n"
     ]
    }
   ],
   "source": [
    "std::thread my_thread(hello);\n",
    "my_thread.join();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d58595cc-9eb6-4242-a6f4-18325eabcf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Concurrent World\n",
      "This is another message from concurrent world\n"
     ]
    }
   ],
   "source": [
    "std::thread lamba_thread([]{\n",
    "    std::cout<<\"Hello Concurrent World\\n\";\n",
    "    std::cout<<\"This is another message from concurrent world\\n\";\n",
    "});\n",
    "lamba_thread.join();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c16e3a-a1eb-4119-a3ae-2ca66a43ffba",
   "metadata": {},
   "source": [
    "# Background Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c467d07d-7d2b-4844-9c12-b427621e3c35",
   "metadata": {},
   "source": [
    "* `detach()` leaves the thread to run in the background without any means of communicating with it\n",
    "    * No longer joinable\n",
    "    * Ownership and control passed to the C++ runtime system\n",
    "* Detached threads often called daemon threads after the UNIX concept of a daemon process that runs in the background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662542bb-0726-454c-9700-c56f60ac5190",
   "metadata": {},
   "source": [
    "# Cooperative Cancellation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0afffae-b923-4c37-b465-ee19ffabd9ed",
   "metadata": {},
   "source": [
    "C++20 provides `std::stop_source` and `std::stop_token` classes to handle a purely cooperative cancellation.\n",
    "\n",
    "The new thread class in C++20 `std::jthread` integrates with `std::stop_token` to support cooperative cancellation.\n",
    "* Destroying a std::jthread calls source.request_stop() and thread.join().\n",
    "* The thread needs to check the stop token passed into the thread function.\n",
    "\n",
    "```cpp\n",
    "void thread_func(std::stop_token st, int arg1, int arg2) {\n",
    "    while(!st.stop_requested()){\n",
    "        do_stuff(arg1,arg2);\n",
    "    }\n",
    "}\n",
    "\n",
    "void foo(int i) {\n",
    "    std::jthread t(thread_func, i, 42);\n",
    "    do_another_stuff();\n",
    "} // destructor requests stop and joins\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c44b2e-db61-48fb-9412-78066ee0ebb8",
   "metadata": {},
   "source": [
    "# Identifying threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29c81ed-e87c-4ace-ba5f-f428225f41e7",
   "metadata": {},
   "source": [
    "Thread identifiers are of type `std::thread::id`\n",
    "\n",
    "* Can be obtained in two ways\n",
    "    * `get_id()` member function\n",
    "    * `std::this_thread::get_id()`\n",
    "* If thread object does not have an associated thread of execution, `get_id()` returns default constructed `std::thread::id` object\n",
    "    * Indicates “not any thread”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "475249c4-22dc-4f41-ba67-75f8e3aa06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <thread>\n",
    "#include <chrono>\n",
    " \n",
    "void foo() {\n",
    "    std::this_thread::sleep_for(std::chrono::seconds(1));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3516a51-0cd6-4fe0-ba8e-c5529f7c541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1's id: 140254193317632\n",
      "t2's id: 140254184126208\n"
     ]
    }
   ],
   "source": [
    "std::thread t1(foo);\n",
    "std::thread::id t1_id = t1.get_id();\n",
    "\n",
    "std::thread t2(foo);\n",
    "std::thread::id t2_id = t2.get_id();\n",
    "\n",
    "std::cout << \"t1's id: \" << t1_id << '\\n';\n",
    "std::cout << \"t2's id: \" << t2_id << '\\n';\n",
    "\n",
    "t1.join();\n",
    "t2.join();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3a325d-e85b-4496-b1ed-f9ccf80ec989",
   "metadata": {},
   "source": [
    "# Sharing data between threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672155f-bc51-48ac-bfa8-761f6794b9b6",
   "metadata": {},
   "source": [
    "* No problem as long as all accesses are read only\n",
    "* Problems begin as soon as at least one threads modifies shared data\n",
    "* Problems often related to **Invariants**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de36f29-a10a-439d-b50e-eba04bfb512b",
   "metadata": {},
   "source": [
    "## Race condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47feda38-5a01-4f26-a26a-935c8a1ad407",
   "metadata": {},
   "source": [
    "<img src=\"img/race_condition.png\" alt=\"Race Condition\" width=\"70%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790dd7b1-6b5f-46de-8861-1d0e2c39f5ae",
   "metadata": {},
   "source": [
    "* Causes non-deterministic program behavior\n",
    "    * Failure in programs expected to be deterministic\n",
    "* Often benign – if all possible outcomes are acceptable\n",
    "    * Example: often the order in which items are added to a queue does not matter – as long as all invariants are maintained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc42cb37-958a-4906-b7cf-e297ebf8be01",
   "metadata": {},
   "source": [
    "## Data Race condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5960c28-f54c-4b15-8f9d-959535242954",
   "metadata": {},
   "source": [
    "<img src=\"img/data_race.png\" alt=\"Data Race Condition\" width=\"70%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee36ca-be8b-4642-8a30-2f2fb221566a",
   "metadata": {},
   "source": [
    "<img src=\"img/data_race_types.png\" alt=\"Data Race Condition Types\" width=\"80%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b15d0c0-ba75-4a45-bea1-31ec21b066da",
   "metadata": {},
   "source": [
    "## Protecting shared data with mutexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e076afa0-0bec-45a5-a775-962477d617e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
