{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4edaa05-2cfe-4189-aac8-9c80f5415d93",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 30px; font-weight: bold;\">Lock-Free Concurrent Data Structures</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c898f183-b4e9-4f13-b686-cc19a0cda8bd",
   "metadata": {},
   "source": [
    "# Lock-based concurrent data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557c4efc-a3b2-460e-b417-d78a8001016c",
   "metadata": {},
   "source": [
    "<img src=\"img/lock_based_approach.png\" alt=\"Lock-based concurrent data structures\" width=\"80%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b6fab-a75f-428d-9ad8-38955e4cfe22",
   "metadata": {},
   "source": [
    "## Blocing vs non-blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5201ad-e91c-4ae6-98f5-eaa444fe6814",
   "metadata": {},
   "source": [
    "* Programs that use mutexes, condition variables, and futures are called **blocking**\n",
    "* They call library functions that will suspend the execution of a thread until another thread performs an action\n",
    "* Thread can’t progress past this point until block is removed\n",
    "* Typically, OS will suspend a blocked thread completely\n",
    "* Programs that don’t use blocking library calls are non-blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c102fde9-d2cd-4754-b3cb-b36b529638f7",
   "metadata": {},
   "source": [
    "# Lock-free structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad27981b-70ba-4110-b2e8-4d2540a025c6",
   "metadata": {},
   "source": [
    "* More than one thread can access the data structure concurrently\n",
    "* If one thread is suspended by the scheduler midway through its operation, other threads must still be able to complete their operation\n",
    "    * Caveat: compare/exchange loops\n",
    "* Can still result in a thread being subject of starvation\n",
    "    * Consequences of “wrong” timing\n",
    "    * One thread makes progress while another one continuously retries its operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74faaa0-6e5f-484c-a509-d3806e2fede3",
   "metadata": {},
   "source": [
    "<img src=\"img/lock_based_vs_lock_free.png\" alt=\"Lock-based concurrent data structures\" width=\"80%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb61fcb-54c4-41ea-8a68-1d3e081a8d93",
   "metadata": {},
   "source": [
    "## Wait-free and Lock-free definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2451da94-3209-49b4-98a0-661fe55a1a36",
   "metadata": {},
   "source": [
    "**Wait-free:** A method is wait-free if it guarantees that every call to it finishes its execution in a finite number of steps. It is **bounded wait-free** if there is a bound on the number of steps a method call can take.\n",
    "\n",
    "**Lock-free:** A method is lock-free if it guarantees that infinitely often some method call finishes in a finite number of steps. Clearly, any wait-free method is also lock-free, but not vice versa. Lock-free algorithms admit the possibility that some threads could starve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6d005c-5c5f-4878-8638-f77ef56ce513",
   "metadata": {},
   "source": [
    "## Advantages of lock-free data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ef7467-f59f-4b09-92ac-c351ebf82a6f",
   "metadata": {},
   "source": [
    "* Performance – some thread makes progress with every step\n",
    "    * In a wait-free DS every thread can make forward progress\n",
    "* Robustness – if a thread dies during an operation, only its data is lost\n",
    "    * If a thread dies while holding a lock, DS is broken forever\n",
    "* Deadlocks impossible – although livelocks may occur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0223f7bf-1017-4a42-a729-1be5102dc971",
   "metadata": {},
   "source": [
    "## Livelock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23cad32-00b4-4e04-95e2-269d21a19dc5",
   "metadata": {},
   "source": [
    "* Two threads concurrently try to change the DS\n",
    "* Actions performed by one cause other to fail and vice versa\n",
    "* Each thread has to continuously restart its operation\n",
    "* Analogy – two people trying to go simultaneously through a narrow gap\n",
    "    * They keep retrying until they agree on an order\n",
    "* Typically short-lived like the scheduling condition that causes them\n",
    "    * Decreases performance rather than preventing progress entirely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d58ae0-72b4-4f32-a26d-1c060ca290bc",
   "metadata": {},
   "source": [
    "## Disadvantages of lock-free data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b34ec40-2c5f-4601-b8e0-981d150b30fb",
   "metadata": {},
   "source": [
    "* Hard to uphold invariants in the absence of mutexes\n",
    "    * Avoiding data races requires atomic operations\n",
    "    * Important to ensure that updates become visible in the correct order\n",
    "* May improve concurrency but decrease overall performance\n",
    "    * Atomic operations can be slower than non-atomic ones\n",
    "    * Hardware must synchronize data between threads\n",
    "    * Performance not necessarily portable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf96808-258c-4807-b6d5-5d6c8300cd8a",
   "metadata": {},
   "source": [
    "# Lock-free Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b127890-e703-4399-b93d-857c6d190ade",
   "metadata": {},
   "source": [
    "## Push Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6ba05b-ee8e-430e-8453-e55d0bfe118d",
   "metadata": {},
   "source": [
    "* The `compare_exchange_weak` helps to always have the last value of the head and not lose track of any node when more than one thread is trying to push an element into the stack\n",
    "* Once the thread has been out of the push method, means that the value was added to the stack without a problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828d981b-c248-45ee-a91f-2d06f5481d32",
   "metadata": {},
   "source": [
    "<img src=\"img/thread_safe_lock_free_push.png\" alt=\"Thread Safe Lock-Free Push\" width=\"80%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c27e43-9ebd-4ce8-a9fe-5be45c0334e4",
   "metadata": {},
   "source": [
    "## Pop Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da3de1f-eea7-48f1-a62d-d0df8efc6bda",
   "metadata": {},
   "source": [
    "### Remarks of the code in the Diagram `C04_stack_pop`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b16c9fd-cfce-4ae4-bc14-f20e41cd74e7",
   "metadata": {},
   "source": [
    "* The hard part in this part of the code is to **not have memory leaks**. C++ is not a garbage collector language like C# or Java. Therefore it is necessary to implement a system to eliminate the pointers and information that are no longer need after the pop.\n",
    "* The pop functionality is made only in the first lines using the `while` to get the last real value of the `head`\n",
    "* The next lines in this approach tries to eliminate the residual pointers when there were already used. However, as it is mentioned in the diagram, there is a *wrong behavior* using this code, when a thread gets the head but it starts again after a complete process in otehr thread."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb8c33-bb0d-44d5-a845-34969ad99b59",
   "metadata": {},
   "source": [
    "### Discussion of the `pop()` with hazard pointers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b41627-7db2-4093-a45c-2ddf8550998f",
   "metadata": {},
   "source": [
    "* In this code a change is made in compare with the other one. It is using the hazard pointer, which is going to verify that an element in the stack is not being used from another thread when wants to be deleted.\n",
    "* Hazard pointers store a list of the nodes in use\n",
    "\n",
    "Although this simple implementation does indeed safely reclaim the deleted nodes, it adds quite a bit of overhead to the process. Scanning the hazard pointer array requires checking `max_hazard_pointers` atomic variables, and this is done for every `pop()` call. Atomic operations are inherently slow—often 100 times slower than an equivalent nonatomic operation on desktop CPUs—so this makes `pop()` an expensive operation. Not only do you scan the hazard pointer list for the node you’re about to remove, but you also scan it for each node in the waiting list. Clearly this is a bad idea. There may well be max_hazard_pointers nodes in the list, and you’re checking all of them against `max_hazard_pointers` stored hazard pointers. Ouch! There has to be a better way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ef31c2-297d-4c97-8e03-4c8f799fa6d9",
   "metadata": {},
   "source": [
    "### Reference Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef96618-1d5a-4c1f-999c-81648a2774e3",
   "metadata": {},
   "source": [
    "* Hazard pointers store a list of the nodes in use\n",
    "* Reference counters stores a count of the of the number of threads accessing each node\n",
    "    * Idea similar to `std::shared_ptr<>`\n",
    "* Why not just using `std::shared_ptr<>`?\n",
    "    * Not guaranteed to be lock free\n",
    "    * A lock-free implementation would impose overheads in many use case scenarios for which lock freedom is not needed\n",
    "    * If `std::shared_ptr<>` was lock-free, problem would be easily solved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0762acb-2a63-47de-9a9d-5f28f037ea0f",
   "metadata": {},
   "source": [
    "### Reference Couting with split counters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc91f99-b593-4d08-9161-5e6556cabde6",
   "metadata": {},
   "source": [
    "* External count kept alongside the pointer\n",
    "    * Increased every time the pointer is read\n",
    "* Internal count kept alongside the node\n",
    "    * Decreased when reader is finished with the node\n",
    "* Sum equal to total number of references\n",
    "* A simple operation reading the pointer will leave the\n",
    "    * External counter increased by one\n",
    "    * Internal counter decreased by one\n",
    "* When the external count/pointer pairing is no longer needed (i.e., node no longer accessible from a location accessible to multiple hreads)\n",
    "    * The value of the external count is added to the internal count\n",
    "    * The internal count is decreased by one\n",
    "    * The external count is discarded\n",
    "* Once the internal count is zero, there are no outstanding references and the node can be deleted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
