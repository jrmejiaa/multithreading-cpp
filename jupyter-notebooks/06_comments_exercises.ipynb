{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d21f40-1d9e-45b5-848c-9ac77609fe4d",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 30px; font-weight: bold;\">Comments about the Exercises</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935ff675-3dcd-44d7-8fe0-6558f5462e8d",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5dc2c1-40f0-4eff-a6bf-ee68c77c9e51",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65bee4-8069-4418-9029-7068ed6a4aa7",
   "metadata": {},
   "source": [
    "* It is important to understand the difference between copy Constructor, Copy-able (copy assignment), Move-constructable and move-able (move assignment)\n",
    "* To make the restrictions it is necessary to use again templates at the beginning of the class and to define the characteristics of a method of this class. The next is an example of this:\n",
    "\n",
    "```cpp\n",
    "template<typename T>\n",
    "class threadsafe_stack {\n",
    "private:\n",
    "    // In order to make a wrapped unique_ptr, we need to create a \n",
    "    // stack with the specific typename\n",
    "    std::stack<std::unique_ptr<T>> data{};\n",
    "    // Mutable is used when we want to change the value inside a const object\n",
    "    mutable std::mutex m{};\n",
    "public:\n",
    "    threadsafe_stack() = default;\n",
    "    \n",
    "    // There is a method to push one element by copy semantics. \n",
    "    // This method only exists if the type is\n",
    "    // copy-able and copy-constructable without exceptions.\n",
    "    template<typename D = T, std::enable_if_t<std::is_same_v<D, T> && \n",
    "                                              std::is_nothrow_copy_constructible_v<D> && \n",
    "                                              std::is_nothrow_copy_assignable_v<D>,\n",
    "                                             bool> = true>\n",
    "    void push(const T &value) {\n",
    "        std::lock_guard<std::mutex> lock(m);\n",
    "\n",
    "        auto unique_ptr = std::make_unique<T>(value);\n",
    "        data.push(std::move(unique_ptr));\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "* In this case the `template` is used in the method to make a comparison regarding to if the type does not throw an exception and is copy constructor and copy assignable. It is necessary in this case to create the `enable_if_t` and `is_same_v`.\n",
    "* When `push` or `pop` an element, it is necessary to block the stack using the mutex as it was mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1cd083-ef2a-4dcb-9e2d-5cf63d633f0c",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b678219-4cc4-46bc-a532-81c38b51155e",
   "metadata": {},
   "source": [
    "* Search for the first variable and what should *happens-before* to fulfil the condition given.\n",
    "* Make the same with all the variables to get the restrictions for the sequential sequence.\n",
    "* Do not **forget** about the sequence before. The element 1.1 should always be happening before 1.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f78570-21ab-4a56-bfbd-88f8fd56465c",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf66fed4-07d0-423f-811c-f574a1c5c82c",
   "metadata": {},
   "source": [
    "* Go to the different codes in the repo to see the diference of sintax.\n",
    "* Conditional variables are prone to spurious and lost wakeups at the moment of using the `notify_all` could lead to problems when use as waiting points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1538738f-4f38-44aa-ba4a-ce09e48ae89b",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0029430a-769d-48e6-bf2d-4b5b77fa1d2b",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871995b-2ccb-432b-8f9a-aaebe3c3e670",
   "metadata": {},
   "source": [
    "First point is quite straight forward. The idea is to use the `fetch_add` method of the atomic variables to add the the `sharedValue` variable the addition. In this case, it does not matter when was added or which thread has added a specific value, the only thing that matters is that the value is not being half seen by any of the threads.\n",
    "\n",
    "* If we dont use `fetch_add` but only `load` and `store` operations, we could see problems and strange behavior, this is not a **data race** but a **race condition** because in the middle of the two operations, the other thread could also make a `load` operations, which would lead to no add the value correctly. However, it is not **data race** because an atomic variable cannot be seen as half done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1b3f36-26b2-4b8c-9b2b-c051bce0dd3a",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788cd735-9e00-481b-a40a-2d7616a00483",
   "metadata": {},
   "source": [
    "### Inter-thread happens before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84aef73-68ce-4bb9-a291-e798e0815c89",
   "metadata": {},
   "source": [
    "Between threads, evaluation A inter-thread happens before evaluation B if any of the following is true\n",
    "\n",
    "* A synchronizes-with B\n",
    "* A is dependency-ordered before B\n",
    "* A synchronizes-with some evaluation X, and X is sequenced-before B\n",
    "* A is sequenced-before some evaluation X, and X inter-thread happens-before B\n",
    "* A inter-thread happens-before some evaluation X, and X inter-thread happens-before B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2de009-a102-4cb3-8902-f595be1ad1ff",
   "metadata": {},
   "source": [
    "### Happens-before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa88e1e-c4f9-4ccb-b2f6-ac8cddd7e055",
   "metadata": {},
   "source": [
    "Regardless of threads, evaluation A happens-before evaluation B if any of the following is true:\n",
    "\n",
    "* A is sequenced-before B\n",
    "* A inter-thread happens before B\n",
    "\n",
    "If one evaluation modifies a memory location, and the other reads or modifies the same memory location, and if at least one of the evaluations is not an atomic operation, the behavior of the program is undefined (the program has a data race) unless there exists a happens-before relationship between these two evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802acc8a-a754-4b22-8806-e55777f60fa1",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99121bf-c940-4c96-a498-a47f3ed54e8a",
   "metadata": {},
   "source": [
    "During the exercise section of this week, we spoke with Fabian about this particular issue that we are trying to consider in this case and why it is possible that the `synchronizes-with` that I show in the diagram is not enough to guarantee that the thread 1 is going to read always **true** in this case. I will try to simplify his explanation in that case here because I found in that meeting that I have not understand the Load/Store communication with memory ordering before.\n",
    "\n",
    "- The Store/Load operations does not guarantee that the last value in the variable is *always read* in other threads. This means, that even if you have a `synchronizes-with` relationship, it could also happen that because of caching you see the false. Before I thought that Load/Store operation if they were seeing in the order that I shown in the time diagram, they will always guarantee that the value is going to be read the last value in the variable. However, it is not the case, even if in the \"Sacred timeline\" shows that execution of events, due to caching in the different threads, the Store/Load operations are not enough. That's why the author said: : \"the problem is that the load *might not see the store*\"\n",
    "\n",
    "- The RMW operations have \"superpowers\". The RMW operations indeed guarantee that you are going to see the **last value** in the variable. The RMW operations are more expensive operations, because they are going to get always the last data that was written (with at least acq_rel of course). \n",
    "\n",
    "In my example of execution time with the code from Listing 3, it is not possible to see always the true from the thread 0. The synchronizes-with is there, but the Load operation from the thread 1 could also see the value from the constructor, and that's why it is not enough to have this synchronizes-with with Store/Load operations. I mean it is there in the author explanation, but very bad explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cce13e-ab18-4510-9339-1443063a5303",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775fb112-39c6-41f8-b248-4605a8132a75",
   "metadata": {},
   "source": [
    "```cpp\n",
    "void lock(int threadID)\n",
    "{\n",
    "    int me = threadID;      \n",
    "    int he = 1 - me;        \n",
    "    interested[me].store(true, std::memory_order_relaxed);\n",
    "    turn.exchange(1 - me, std::memory_order_acq_rel);\n",
    "    while (interested[he].load(std::memory_order_acquire) && turn.load(std::memory_order_relaxed) == he)\n",
    "        continue; //spin\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2620ef71-aa93-4c5a-acb5-4181b6da1d5e",
   "metadata": {},
   "source": [
    "The main part why this is enough to solve the problem with the mutex based on atomic variables is the follows:\n",
    "\n",
    "* This time the `turn` variable is using a RMW operation, which is going to get the last value in the variable and creates a *happens-before* relationship with the last written `store` operation. This would make that all the previous operations in the other thread can be seen. This implies that the `interesed[he]` would receive the last value written when operates the `load` in loop. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eccf89-244c-4568-9661-32dd4d28142d",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaf6fa3-dbc1-47bd-b465-b7838a965932",
   "metadata": {},
   "source": [
    "The idea behind the exercise fourth is to use the parallel programming to increase the performance of a code. The code is not important but the idea behidn how to make it faster. The code has two important parts, which are the ones that have the operations that we can automated.\n",
    "\n",
    "* `all_pairs_shortest_paths`: This function has two nested for loops. The idea in this case is to be aware if there is variables that needs to communicate information with other threads. In this case, there are not variables that needs to communicate with other threads. An interation of the first loop is going to set the value of the local distances from this node into the return variable of this function `all_distances`. However, those values are not read for other thread, therefore it is possible to make a simple `for_each` with parallel execution to make this parallel without race condition or data condition.\n",
    "* `calculate_largest_smallest_path`: This function has shared memory between the for statements. Therefore it would need a lock-based or lock-free strategie to avoid data race conditions. In this case it were shown during the solution three solutions:\n",
    "    * lock-based: It is the easiest version, it would only blocks the information when it needs to be changed. This solution create s a vector of `mutexes` to lock the specific data regarding to that position to avoid block all the data unnecessary.\n",
    "    * lock-free: Here the solution showed two possible approaches: `std::atomic` and `std::atomic_ref`. Both of them works under the same principles, but the `std::atomic` needs to create a vector all atomic variables which is more expensive in terms of resources than making an atomic reference when necessary. Therefore the overload is less than the creation of the whole array of atomic items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e700ab-176f-469f-9e3d-48394086c946",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c33d6-b805-4c45-aa6e-e666cd52e85b",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117c2c8c-91b1-4987-a1a7-f16f5ac53ad5",
   "metadata": {},
   "source": [
    "<img src=\"img/multiverse_example_2.jpg\" alt=\"Multiverse example with FIFO\" width=\"80%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368be12f-5c80-45c7-a0bd-e13671bcc14d",
   "metadata": {},
   "source": [
    "* This example in the image is sequential consistency because there is a possible single thread execution that can be made to reproduce this behavior. Because of that the two conditions are fulfil.\n",
    "* However, it is not **linearizable** because during the time of execution of every operation, it cannot be possible to maintain the correctness of the implementation. Since the beginning of the operation `enq(y)` the operation `enq(x)` has been already finished. Because of that, the result of the `deq(y)` should not be possible, the real result should be `x`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db16947a-a142-4436-ac24-223d9bb7c2f4",
   "metadata": {},
   "source": [
    "<img src=\"img/ex5_task1.png\" alt=\"Multiverse example with FIFO\" width=\"80%\" style=\"margin: 0 auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c434df77-e24c-4442-9032-3ea6905ec516",
   "metadata": {},
   "source": [
    "* For this exercise the reasoning is the same. We can found a single thread execution that delivers the same result that the given by this history. Because of that the execution is *sequential consistency*. For the linearizable, the operations should be execute during its invocation and return and delivers a correctnes result. In that case, the next execution fullfil this condition:\n",
    "\n",
    "    * C_r.write(2), B_r.write(1), A_r.read(1), B_r.read(1)\n",
    "\n",
    "This confirms that the system is **linearizable**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56119825-ac4d-4781-b6bd-59054c89a8f9",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea3e22-6844-4ccb-865a-e5762406c768",
   "metadata": {},
   "source": [
    "* I should always work with two trheads to find the critical points where the information could be wrong. In this case after an execution with two threads, I have not find any error in the execution, but it was because I did not stop in the critical points. As it was mentioned in the solution: \n",
    "    * The implementation is not linearizable. Suppose the queue is empty. Thread A calls enq(x) and thread B calls enq(y) simultaneously. Further suppose that thread A completes the loop at line 11 first, and a slot is reserved by thread A. However, due to some reasons thread A is stuck between line 13 and line 14. While in this time, thread B finishes the call to enq(y), and start another call to deq(). Since x has not been written to its slot by A, this deq() will throw at line 24. This execution history violates the sequential specification of FIFO: Since y has been enqueued, the call to deq() should return y, not throw an exception."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b78412f-1fde-4114-a38d-842f64193612",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f830f6-4a74-4c17-93a1-bccc5d04656a",
   "metadata": {},
   "source": [
    "* The implementation of the exercise 6 follows something similar to the implementation of lock-free data structures during the 05 Slides of the Lecture. The idea is always to protect variables that cannot be atomic. In this case, the `data` array is not an atomic variable and therefore, we need some strategies to protect that only one thread could be access the information in a concurrent matter. This is made using the next strategie:\n",
    "    * Use `writers` while loop to allow only one thread at the time in the array. This would lead to maintain waiting other threads for the access. However, this also means that two threads that wants to update a different position of the array cannot do that.\n",
    "    * Use `history` atomic variable to avoid that a read and write operation happens at the same time and cause a data race condition. The atomic variable in this case is used with `fetch_add` and *happens-before* relationship to avoid that two threads one read and one write happens at the same time creating an undefined value during the read process.\n",
    "    \n",
    "* The last point is really straight forward, it would use the `while` loop and the `compare_exchange_weak` strategie seen in the Lecture to choose the maximum value. The only difference in that case, is that the first use the RMW approach with the `compare_exchange_weak` and the second one the read-and-conditional-store instruction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
